from fastapi import FastAPI, UploadFile, File
from fastapi.responses import FileResponse
import os
# from fastapi.middleware.cors import CORSMiddleware
import whisper
from transformers import pipeline
import sys
sys.path.append(r"C:\AI_Coop\Homework\Week3\voice_assistant\CosyVoice")  # æ ¹æ®ä½ çš„å®é™…è·¯å¾„è°ƒæ•´
from CosyVoice import CozyVoice
import tempfile

app = FastAPI()

# ========== Step 1: ASR ==========
#Load Whipser model(ç¬¬ä¸€æ¬¡ä¼šä¸‹è½½æ¨¡å‹)
asr_model = whisper.load_model("small")

def transcribe_audio(audio_bytes):
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
        tmp_file.write(audio_bytes)
        tmp_file.flush()
        result = asr_model.transcribe(tmp_file.name)
    text = result["text"].strip()
    print(f"[ASR Output] User said: {text}")
    return text

# ========== Step 2: LLM ==========
# è½½å…¥è½»é‡çº§æ–‡æœ¬ç”Ÿæˆæ¨¡å‹ï¼ˆå å†…å­˜å°‘ï¼Œæ–¹ä¾¿è°ƒè¯•ï¼‰
llm = pipeline("text-generation", model="distilgpt2")

# ç®€å•å¯¹è¯å†å²ï¼Œä¿å­˜æœ€è¿‘ 5 è½®
conversation_history = []

# app.add_middleware(
#     CORSMiddleware,
#     allow_origins=["http://127.0.0.1:5500"],  # æˆ–è€… ["*"] ä»…å¼€å‘æ—¶ç”¨
#     allow_credentials=True,
#     allow_methods=["*"],
#     allow_headers=["*"],
# )

def generate_response(user_text):
    conversation_history.append({"role": "user", "text": user_text})
    # æ„é€  promptï¼ˆåªä¿ç•™æœ€è¿‘ 5 è½®å¯¹è¯ï¼‰
    prompt = ""
    for turn in conversation_history[-5:]:
        prompt += f"{turn['role']}: {turn['text']}\n"
    # è°ƒç”¨ LLM
    outputs = llm(prompt, max_new_tokens=100)
    full_output = outputs[0]["generated_text"]
    # å–"assitant:"ä¹‹åçš„éƒ¨åˆ†
    bot_response = full_output.split("assistant:")[-1].strip()
    conversation_history.append({"role": "assistant", "text": bot_response})
    print(f"[LLM Output] Assistant said: {bot_response}")
    return bot_response


# ========== Step 3: TTS ==========
tts_engine = CozyVoice()

def synthesize_speech(text, filename="response.wav"):
    tts_engine.generate(text, output_file=filename)
    return filename

# ========== Step 4: æ•´åˆåˆ° API ==========
@app.post("/chat/")
async def chat_endpoint(file: UploadFile = File(...)):
    # è¯»å–ä¸Šä¼ çš„éŸ³é¢‘
    print("ğŸ“¥ Received request")
    audio_bytes = await file.read()
    
    # ASR â†’ LLM â†’ TTS
    # Step 2: ASRï¼šè½¬å½•æˆæ–‡å­—(è¯­éŸ³è¯†åˆ«)
    user_text = transcribe_audio(audio_bytes)
    print("[ASR Output] User said:", user_text, flush=True)  # è°ƒè¯•è¾“å‡º

    # Step 3: LLMï¼ˆç”Ÿæˆå›å¤ï¼‰
    bot_text = generate_response(user_text)
    print("[LLM Output] Bot said:", bot_text, flush=True)

    # (åˆæˆè¯­éŸ³)
    audio_path = synthesize_speech(bot_text)
    

    # è¿”å› response.wav çš„å®Œæ•´è·¯å¾„ï¼ˆæ¨èä½¿ç”¨ç»å¯¹è·¯å¾„ï¼‰(è¿”å›wavæ–‡ä»¶)
    # file_path = os.path.abspath("response.wav")
    return FileResponse(audio_path, media_type="audio/wav")
    